# Slide 1 [0:44]

I wanted to contribute to TensorFlow so I started studying the codebase.  I noticed
that lots of exceptions generated by ops were vague, unhelpful, or even wrong.
Top-level documentation often didn't precisely define what combinations tensor shapes
or ranks, or dtypes were allowed.

I sensed there was an opportunity to solve both of these problems by identifying a
way to express these input constraints and using that to generate integrity checks
and documentation.  As an added bonus, this approach also provides a way to generate
unit tests for testing the integrity check mechanism.

# Slide 2 [show convolution_docs.jpg]

Before getting into how it's implemented, I wanted to show some of the results to
illustrate what it does, and motivate a sense of the problem.  I mentioned that the
documentation doesn't precisely define allowed inputs.  Looking at the documentation
for tf.nn.convolution, which combinations of shapes, formats and dtypes does it
accept?  There is no mention of allowed dtypes for input tensor, although they do
mention that the filter type must be the same as the input type.

Also, the docs implies that there must be exactly one batch dimension.

# Slide 3 [show conv_explain.txt]

Here is documentation autogenerated by opschema for tf.nn.convolution.  It has
several sections.  The first two sections, Indexes and Signatures, introduce
intermediate concepts that I'll explain later.  Basically, though, they serve to
partition tensor shapes into semantic groups.  This layer of indirection provides a
handle to express relationships and constraints between the shape components.

This documentation is validated against the actual behavior of the tf.nn.convolution
op using over 10 thousand generated test cases.  The test cases are generated
combinatorically by applying the same internal constraints that generated the
documentation.

In this particular case of tf.nn.convolution, there are four discrepancies between
this validated documentation and the official one.  First, the official docs imply
that only 1 batch dimension is allowed.  In fact, batch dimensions from 1 to 5 all
work (perhaps more).  Second, the official docs imply that the input_channel and
filter_input_channel must be the same (they call it in_channels in both input and
filter).  In fact, the in channel in the filter merely needs to evenly divide that of
the input.  Third, although the docs correctly state that the input and filter dtypes
must match, there is no mention of what dtypes are accepted.  opschema tests all of
the possible dtypes and notes which raise an exception.  Fourth, the official docs
make no mention of certain unimplemented combinations of dtype, rank and layout.
opschema discovers these and has a mechanism for recording the excluded ones.  This
is shown in the excluded dtype combos section.

You will notice that there are more semantic indexes than just those that explicitly
appear in tensor input shapes.  Indexes are appropriate to track any shape-like
quantities, including intermediate quantities.  In this case, stride, dilation,
padded dimensions are all shape-like quantities that participate in the shape algebra
important in validation.

The core ideas to make this all possible are easiest to illustrate using a simpler
toy example function.

# Slide 4 

[
soda_original:softdrink_revenue
soda_pred_simple.svg
] 

Here I want to show a toy function, 'softdrink revenue', to illustrate the challenge.
This is a function for estimating the revenue selling small, medium or large
soft drinks as a function of the price you choose.  The function requires that small
price be in a certain range, and that the prices are increasing.  These requirements
produce three separate artifacts - documentation, validation logic, and unit test
generation.  All three of these arise more or less automatically from the core ideas
of 'in range' and 'greater than'.

This implementation is not bad as it is.  Imagine though that you have a library
of many functions, and many of them share such input constraints like the ones shown.
It would be nice to have a system for concisely expressing such input constraints,
and getting these three artifacts automatically for each function in the library.

Notice that we can express the constraints as a three-node dependency graph, with the
nodes corresponding to small price, medium price, and large price, with dependencies
shown.

Also, notice that each piece of validation logic has a test and a message.  The test
requires only the values, while the message generation requires the values and the
names of the arguments.  Overall, the validation logic performs a sequence of tests
to validate each quantity, and some tests depend on previously validated quantities.
Implicitly there is a graph structure here, with each node corresponding to a test
and a possible error message if the test fails.

# Slide 5 [01:17]

[
soda_original:gen_softdrink_revenue_tests
soda_pred_graph:predicate_graph
soda_pred_graph.svg
]

Here I want to show the abstract idea of a predicate graph.  This is a computation
graph in which each node holds two functions - a test function and an error message
function as well as an associated value.  It is a DAG, and the nodes are evaluated in
topological order.

To evaluate the graph, the test function is called with the node's current value as
well as the values of its parent nodes.  The graph implements the classic
short-circuiting evaluation.  If any node test fails, the error message function
produces the final error message.  If all tests succeed, the predicate as a whole
succeeds.

In this example, each node represents a top-level input argument for the function,
and the values are provided during the call.  In the more general case, nodes could
represent intermediate values that are imputed from the input arguments.

In contrast, the constraints don't need to be defined in a topological order.  The
graph construction automatically induces such an order which can be discovered
programmatically.

# Slide 6 [01:43]

[
soda_pred_graph:InputConstraints
]

Now, the validation logic is expressed as a predicate graph.  The nodes contain the
tests and error message functions, which are used among many target functions.  Here,
in the class input constraints, we have an API for declaring these constraints.  Each
function constructs part of a predicate graph.  Once constructed, the validate
function automatically runs this graph.

Below we see how the API is used.  For each target function (in this case softdrink
revenue is our target function), the constraints are added.  Then, inside the target
function, the constraint logic is a simple call to 'validate'.

For the low level concepts of 'in range' and 'is greater', there are two
functions - a test function and an error message function.  Also, note that the input
constraints class provides an API function to declare each of these constraints.

In the more general case, input constraints may be used to express more complex
constraints that use a combination of lower level test / error functions, and in
general create more than one predicate node.

While this does produce some coupling because all target functions, softdrink revenue, etc,
now depend on the same lower level functions, it is not bad, because these test and
error message functions are very elementary and terminal.

Now how can we use this system to construct a unit test generator?

# Slide 7 [00:37]

[
soda_original:gen_softdrink_revenue_tests
generators:generate_all
soda_pred_graph.svg 
]

The original generator is implemented as a nested loop of three
individual generators, one for each argument value.  The second and third generator
are invoked multiple times, and accept as arguments values generated by previous
generators.  This is what allows the overall generator to uphold relationships
between the values.

On the right is a generalization to an arbitrary graph structure.  The function on
the right invokes each generator in topologically sorted order, and automatically
provides the current parent node settings to each generator function.


# Slide 8 [01:18]

[Show soda_gen_graph.py:1-67]

So now, for each low level constraint concept 'in range' and 'is greater', we add a
third function - the generator function.  Its job is to generate a sampling of valid
and some invalid values for that constraint.  The valid values test that the
predicate correctly passes them, and the invalid ones test that the predicate raises
an appropriate error.

Also, the input constraints class has now been extended, so that each API call also
constructs part of the generator graph.   And, it has a generate method which simply
generates from the generator graph.

The top-level softdrink generator function is just a call to the op's generate
method.

At this point you might notice that the generator graph and predicate graph have the
same structure.  And, perhaps there could be a more deluxe node type that can do both
functions, and just have one graph.

Although this would be possible in this toy example, the more general graphs include
nodes that represent intermediate values that don't correspond to target function
input arguments.  For TensorFlow ops, I tried very hard to discover a way to
represent constraints such that I could have just one graph, but in the end did not
find one.

# Slide 9 [1:20]

[
soda_constraints.svg
conv_constraints.svg
] 

To summarize the toy example in a picture, I defined three top-level constraints on
the input arguments, which you can see in the graph.  The ovals show the input
arguments to the softdrink revenue function, and the rectangles are the constraints.

For TensorFlow, such a summary might look like the graph below, which shows
tf.nn.convolution.  Here we can see that data format, and padding both have an
options constraint on them.  strides and dilations have a relationship such that at
most one of them can have non-1 components.  Tensor Dtypes are constrained as you can
see.  Finally, a more complex constraint exists between the tensor shapes and the
data format.

This constraint says, if data format is 'channel first', like NCH or NCHW for
example, then the input tensor shape is interpreted as batch dimensions, a single
input channel, and then input spatial dimensions.  Otherwise, the spatial and channel
dimensions are switched.

Additionally, the number of filter spatial dimensions must match those in the input.
And the filter input channel must be evenly divisible by the input channel dimension.

In order to express all of this logic in a way that can be reusable across many
tensor operations, I introduced a few intermediate quantities.

# Slide 10 [1:12]

[Show index_constraints.svg]

The first idea is the named group of dimensions known as an 'index', which has a long
name, like 'batch' or input_spatial, and a one-letter code, such as 'b', or 'i'.  The
index is a placeholder object.  One can place constraints on one or more indices in
the same way as constraints on input arguments.

Then, the notion of a signature is introduced.  A signature is an ordered sequence of
indices which defines an interpretation of a tensor shape.  For example, in
tf.nn.convolution, the filter tensor has a signature of 'filter_spatial',
'filter_input_channel', 'filter_output_channel', or 'flo' in one-letter-code.  This
is general with respect to the ranks of individual indexes.  For example,
filter_spatial can take on a rank of 1, 2, or 3.  But, in all cases, the signature is
still just flo.

So, tensor shapes are interpreted through the signature, such that each dimension
belongs to one of these semantic index objects.

Index objects are useful as handles to attach constraints on the rank or relation
between dimensions.  For example, shown here are the actual constraints on indexes
for tf.nn.convolution.

# Slide 11 [1:04]

[Show layout_problem.txt]

Now we have a robust and flexible way to express constraints on TensorFlow op inputs.
In principle, the existing predicate graph could validate them and detect which
constraints are violated.  However, consider the following situation.

Here we have a partial display of a call for tf.nn.convolution.  It is a 2D
convolution, and the data format is given as NCHW.  This leads to the interpretation
on the dimensions of input.shape as shown, with input_channel = 100.  Note that 100
is not divisible by the filter input channel = 3, so the constraint is violated.

However, it could easily be the case that the user intended this as a channel last
layout, but erroneously provided data format of NCHW.  It would certainly be useful
to suggest this as a possible solution.

Unfortunately, in order to detect that suggestion, we need a new kind of search.  To
achieve this, it turns out one can use a generative graph search but filtered to
detect only those settings which come closest to the provided inputs.  These
represent the most likely candidates.

We can still use the generator graph but a modified search as follows.

# Slide 12 [1:08]

[ generators: generate_all (on left)
  generators: generate_nearest (on right)
]

Shown here is the original graph generator function that was used for generating
valid and invalid test cases.  This same idea can be modified to generate hypotheses
that match or come close to (within a certain edit distance) an observed set of
values.  This is useful to solve the problem of generating good suggestions to the
user.

Note that using a large enough max_edits is equivalent to the full set of results.  
Before, I used a generator graph that yields both valid and invalid input
combinations.  Here, I use a graph that only outputs valid combinations.

Then, with this graph, using a max edits of zero, this becomes a predicate to test
correctness of the observed values.  Then, if the predicate fails with zero edits, I
can re-run it with max edit of 1.  This will find any correct inputs within an edit
distance of 1, if they exist.

This approach solves the suggestion problem previously.  It would produce two
suggestions - one to change data format and keep channel dimensions the same.  The
second, to change one or the other channel to satisfy the divisibility constraint.

# Slide 13

[Transition]

To recap, I talked about the core concepts of the predicate graph and generator
graph and how they are used to perform validation logic and generate unit tests.  I
also showed a filtered mode for searching a generator graph within a certain edit
distance, which can be used to generate suggested edits to an incorrect input.

In the next section I want to show some examples of test tensorflow op calls that are
designed to fail, and then compare the Tensorflow generated exception with the
message produced from opschema.

In these examples you can see the advantage of opschema.  The erroneous arguments are
always identified by name.  In cases of shape error, opschema shows its
interpretation of the shape in terms of index groups.

# Slide 14

[show error_examples.txt]

Here we see some examples of erroneous tensorflow op calls.  These test cases are
generated by opschema.  The actual call is shown on the first line.  Then, you can
see the TensorFlow exception, and finally, the message issued by opschema.

...

Next, I want to show the complete generator graph for tf.nn.convolution.  This graph
is automatically constructed from the schema definition.  It is what generates all of
these test cases.  


# Slide 15

[show tf.nn.convolution.gen.svg]

Here is the actual generator graph for tf.nn.convolution.  It is automatically
constructed by the opschema API calls made in the convolution schema.  Recalling the
recursive, combinatoric generation process, I'll describe how this generates many
thousands of different test inputs for the op.

Overall, notice that the nodes highlighted in red correspond to actual arguments.
Everything else is an intermediate quantity used to construct these outputs.  Recall
that the graph generates both valid and invalid inputs.  Given the combinatorial
nature, there can be exponentially many items generated.

The top right portion generates all combinations of index ranks - that is, the number
of dimensions for each semantic Index.  In the case of convolution, the only choices
to make are the number of batch and number of spatial dimensions.  Since input
spatial and filter spatial are equivalent, the total combinations here are just 15 -
5 batch times 3 spatial.

The bottom part generates the signatures, starting from an abstract notion of a
'layout'.  The layout in this case is the notion of either 'channel first' or channel
last.  It is one aspect of the data format argument, except rank agnostic.

The IndexRanks node simply aggregates all of the combinations into a map of index
name => rank.  Similarly, the SigMap aggregates signatures of each argument into a
map of arg_name => signature.


# Slide 16

[Selected schema API calls]









